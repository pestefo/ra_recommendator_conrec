id	title	summary
9084	vslam eigen and compile_error	"<div class=""snippet""><p>Hello,</p>

<p>I am trying to compile vslam as instructed but halting at some error mentioned below:</p>

<p>Is there anything that i am suppose to make link to eigen3 externally?</p>

<blockquote>
  <p>[rosmake-3] Finished &lt;&lt;&lt; rosnode
  ROS_NOBUILD in package rosnode <br/>
  [rosmake-3] Starting &gt;&gt;&gt;
  image_transport [ make ] <br/>
  [rosmake-3] Finished &lt;&lt;&lt;
  image_transport ROS_NOBUILD in package
  image_transport <br/>
  [rosmake-3] Starting &gt;&gt;&gt; cv_bridge [
  make ] <br/>
  [rosmake-3] Finished &lt;&lt;&lt; cv_bridge
  ROS_NOBUILD in package cv_bridge <br/>
  [rosmake-3] Starting &gt;&gt;&gt;
  image_geometry [ make ] <br/>
  [rosmake-3] Finished &lt;&lt;&lt;
  image_geometry ROS_NOBUILD in package
  image_geometry <br/>
  [rosmake-3] Starting &gt;&gt;&gt; rosmsg [ make
  ] <br/>
  [rosmake-3] Finished &lt;&lt;&lt; rosmsg
  ROS_NOBUILD in package rosmsg  No
  Makefile in package rosmsg <br/>
  [rosmake-3] Starting &gt;&gt;&gt; rosservice [
  make ] <br/>
  [rosmake-3] Finished &lt;&lt;&lt; rosservice
  ROS_NOBUILD in package rosservice <br/>
  [rosmake-3] Starting &gt;&gt;&gt; roswtf [ make
  ] <br/>
  [rosmake-3] Finished &lt;&lt;&lt; roswtf
  ROS_NOBUILD in package roswtf <br/>
  [rosmake-3] Starting &gt;&gt;&gt; tf [ make ] <br/>
  [rosmake-3] Finished &lt;&lt;&lt; tf
  ROS_NOBUILD in package tf <br/>
  [rosmake-3] Starting &gt;&gt;&gt; nav_msgs [
  make ] <br/>
  [rosmake-3] Finished &lt;&lt;&lt; nav_msgs
  ROS_NOBUILD in package nav_msgs <br/>
  [rosmake-3] Starting &gt;&gt;&gt;
  dynamic_reconfigure [ make ] <br/>
  [rosmake-3] Finished &lt;&lt;&lt;
  dynamic_reconfigure ROS_NOBUILD in
  package dynamic_reconfigure <br/>
  [rosmake-3] Starting &gt;&gt;&gt; stereo_msgs [
  make ] <br/>
  [rosmake-3] Finished &lt;&lt;&lt; stereo_msgs
  ROS_NOBUILD in package stereo_msgs <br/>
  [rosmake-2] Finished &lt;&lt;&lt; bpcg [PASS] [
  1.40 seconds ]                                                                                                                   [rosmake-1] Finished &lt;&lt;&lt;
  vocabulary_tree [PASS] [ 1.51 seconds
  ] <br/>
  [ rosmake ] Last 40 linesame_common:
  3.5 sec ]                                                                                               [ 1 Active 51/54 Complete ]
  {-------------------------------------------------------------------------------   /opt/ros/cturtle/stacks/geometry_experimental/eigen3/include/Eigen3/src/Core/SelfAdjointView.h:206:
  error: ‘SelfAdjoint’ was not declared
  in this scope <br/>
  /opt/ros/cturtle/stacks/geometry_experimental/eigen3/include/Eigen3/src/Core/SelfAdjointView.h:206:
  error: ‘Upper’ was not declared in
  this scope <br/>
  /opt/ros/cturtle/stacks/geometry_experimental/eigen3/include/Eigen3/src/Core/SelfAdjointView.h:206:
  error: template argument 3 is invalid 
  /opt/ros/cturtle/stacks/geometry_experimental/eigen3/include/Eigen3/src/Core/SelfAdjointView.h:212:
  error: ‘SelfAdjoint’ was not declared
  in this scope <br/>
  /opt/ros/cturtle/stacks/geometry_experimental/eigen3/include/Eigen3/src/Core/SelfAdjointView.h:212:
  error: ‘Lower’ was not declared in
  this scope <br/>
  /opt/ros/cturtle/stacks/geometry_experimental/eigen3/include/Eigen3/src/Core/SelfAdjointView.h:212:
  error: template argument 3 is invalid 
  /opt/ros/cturtle/stacks/geometry_experimental/eigen3/include/Eigen3/src/Core/SelfAdjointView.h:231:
  error: ‘SelfAdjoint’ was not declared
  in this scope <br/>
  /opt/ros/cturtle/stacks/geometry_experimental/eigen3/include/Eigen3/src/Core/SelfAdjointView.h:231:
  error: ‘Lower’ was not declared in
  this scope <br/>
  /opt/ros/cturtle/stacks/geometry_experimental/eigen3/include/Eigen3/src/Core/SelfAdjointView.h:231:
  error: template argument 3 is invalid 
  /opt/ros/cturtle/stacks/geometry_experimental/eigen3/include/Eigen3/src/Core/SelfAdjointView.h:237:
  error: ‘SelfAdjoint’ was not declared
  in this scope <br/>
  /opt/ros/cturtle/stacks/geometry_experimental/eigen3/include/Eigen3/src/Core/SelfAdjointView.h:237:
  error: ‘Upper’ was not declared in
  this scope <br/>
  /opt/ros/cturtle/stacks/geometry_experimental/eigen3/include/Eigen3/src/Core/SelfAdjointView.h:237:
  error: ‘Dynamic’ was not declared in
  this scope <br/>
  /opt/ros/cturtle/stacks/geometry_experimental/eigen3/include/Eigen3/src/Core/SelfAdjointView.h:237:
  error: template argument 3 is invalid 
  /opt/ros/cturtle/stacks/geometry_experimental/eigen3/include/Eigen3/src/Core/SelfAdjointView.h:237:
  error: template argument 4 is invalid 
  /opt/ros/cturtle/stacks/geometry_experimental/eigen3/include/Eigen3/src/Core/SelfAdjointView.h:255:
  error: ‘SelfAdjoint’ was not declared
  in this scope <br/>
  /opt/ros/cturtle/stacks/geometry_experimental/eigen3/include/Eigen3/src/Core/SelfAdjointView.h:255:
  error: ‘Lower’ was not declared ...</br/></br/></br/></br/></br/></br/></br/></br/></br/></br/></br/></br/></br/></br/></br/></br/></br/></br/></br/></br/></br/></br/></br/></br/></br/></br/></br/></br/></br/></br/></br/></br/></p></blockquote><span class=""expander""> <a>(more)</a></span></div>"
9097	How can I get a unique device path for my Arduino/FTDI device	"<p>I'd like to be able to access my Arduino that uses an FTDI USB-Serial device with a unique path. However, the order of /dev/ttyUSB devices depends on which device is plugged in first or USB bus initialization during the boot order. I'd like consistent paths across reboots so that I can use those paths in my launch files.</p>
"
9107	Corrected Odometry from GMapping / Karto?	"<p>I've been building (2D) maps using GMapping, and visualizing the results in rviz. So far, so good. However, the tf frames that are available (/odom -&gt; /base_link, most importantly) represent the original, dead-reckoning, uncorrected odometry.</p>

<p>So far as I can tell, GMapping and Karto don't publish an extra, ""corrected odometry"" frame that I could use to visualize the current best hypothesis about the robot's pose.</p>

<p>Have I missed something, or do I need to put in a feature request?</p>
"
9130	Visualizing continuous and revolute joint types in rviz	"<p>When creating a URDF file for a robot with a head on a pan and tilt mechanism, whenever I try to use a joint type ""continuous"" or ""revolute"" in a manner similar to that shown in the tutorials the model is displayed within Rviz as a disorganized jumble.  If I change the joint type to ""fixed"" then the model displays normally.  The model also seems to check out ok using check_urdf, and no URDF errors show up when Rviz is loading.  This seems to be a bug, since the same thing happens with the tutorial file 06-flexible.urdf</p>

<p>I'm using the current cturtle full binary installation on Ubuntu 10.10.</p>
"
9135	How can multiple robots communicate using ROS?	"<p>For many applications, communication between robots is necessary. What is currently the recommended best practice for achieving that?</p>
"
9159	How much space is required for a complete install of cturtle-base?	"<p>I am installing it on my beagleboard ubuntu distro. I need to know how big of an sdcard I need.</p>
"
9163	How do I set up a ROS mirror?	"<p>At my university, we have several computers that have ROS installed on them.  If I have access to a server, how do I set up a mirror of the ROS Ubuntu repository to speed up installing ROS packages?</p>
"
9166	How to install ROS on BeagleBoard Ubuntu 10.10?	"<p>Any useful info please.</p>
"
9208	How to check xacro syntax like check_urdf?	"<p>Hello!</p>

<p>I would like to do a command line syntax check of an Xacro robot model similar to the one used for non-xacro files which is:</p>

<p>$ rosrun urdf check_urdf model.urdf</p>

<p>I know I can generate a temporary URDF file from my Xacro file using:</p>

<p>$ rosrun xacro xacro.py model.urdf.xacro &gt; tmp.urdf</p>

<p>and then run 'rosrun urdf check_urdf' on that file.  But for some reason I can't figure out how to simply pipe the two commands together into one command.  Can it be done?</p>

<p>Thanks!
patrick</p>
"
9210	problem with kinect tutorial.	"<p> Hi, 
I'm new to kinect and ROS, and am using Ubuntu 10.10. 
After following the instructions at  <a href=""http://www.ros.org/wiki/kinect"">http://www.ros.org/wiki/kinect</a>  and  <a href=""http://www.ros.org/wiki/kinect/Tutorials/Getting%20Started"">http://www.ros.org/wiki/kinect/Tutori...</a> , I still can not getting any point clouds from the kinect.  </p>

<p>From the RVIZ, it says ""no message received"" for the TOPIC under pointCloud2.
Also, the following error in the console: </p>

<p>+++++++++++++++++</p>

<p>... </p>

<p>[Stream 70] Expected 1748 data bytes, but got 1908. Dropping... </p>

<p>[Stream 70] Expected 1748 data bytes, but got 1908. Dropping... </p>

<p>[kinect_driver-4] process has died [pid 30244, exit code -4]. 
log files: /home/blurpc2/.ros/log/93cd600e-4130-11e0-99b0-000e7faeafc1/kinect_driver-4*.log </p>

<p>+++++++++++++++++ </p>

<p>What did I miss? 
Thanks in advance! </p>
"
9259	How to synchronize tfMessage and Image messages?	"<p>Hi there, 
I tried to use message_filters in order to synchronize a tfMessage and an Image messages in code like this:</p>

<pre><code> message_filters::Subscriber&lt;Image&gt; image_sub;
 message_filters::Subscriber&lt;tf::tfMessage&gt; tf_sub;
 tf_sub.subscribe(nh_, ""/tf"", 1);
 image_sub.subscribe(nh_, ""image"", 1);
 TimeSynchronizer &lt;Image, tf::tfMessage&gt; sync(image_sub, tf_sub, 10);
</code></pre>

<p>Unfortunately it turns out that the compilation fails because the tfMessage has no Header block. Here is the error message:
""""""
/opt/ros/diamondback/stacks/ros_comm/utilities/message_filters/include/message_filters/sync_policies/exact_time.h:126: error: ‘value’ is not a member of ‘ros::message_traits::TimeStamp&lt;tf::tfmessage_&lt;std::allocator&lt;void&gt; &gt;, void&gt;’
""""""</p>

<p>Would anyone know of an alternative to what I am trying to achieve above? Does tf_listener maybe support an option of returning the whole TF tree (tfMessage)?</p>

<p>thx and best, D.</p>
"
9261	low rate of stereo prosilica cameras for face_detector	"<p>I'm using a pair of prosilica cameras on care-o-bot, receiving images (left, right, disparity) at rate of about 2 hz, few synchronized triples, which leads to use _approximate_sync:=True _queue_size:=10 in stereo_proc and stereo_view</p>

<p>now face_detector is not working for this pair, while it works fine with a recorded bag video (test), has anyone any idea? suggession, please? </p>
"
9273	Using version control git for ROS development	"<p>Hi,</p>

<p>I am in favor of git in using version control. I would like to know the best practise to do it since I have my own node (myNode) in /opt/ros/diamondback/stacks/myNode.</p>

<p>Should I wrapped the myNode folder/node with repo01.git(for example)? I mean the path now becomes /opt/ros/diamondback/stacks/repo01.git/myNode.</p>

<p>Is there any better way doing it?</p>

<p>Thanks in advance..</p>

<p>-alfa-</p>
"
9287	Are opencv samples in diamondback debs?	"<p>I recently upgraded to diamondback release (installed on Ubuntu 10.04 from apt-get). As I recall, the samples for opencv used to be in the opencv2 package directory -- however, it appears they no longer are? Am I looking in the wrong place or is this due to the cleanup that was done to reduce the size of the .debs? </p>
"
9343	Custom simulation using Stage	"<p>Hi, </p>

<p>I want to simulate a custom robot using ROS Diamondback. I figured that Stage is the package I should be using for simulation. I have read up the documentation on setting up a .world file for my simulation and have a world file with a robot and the intended simulation arena. However I am stuck as to how to proceed further. I have some code which does controlling/path planning for my robot, but how do I integrate the code with Stage ? </p>

<p>Could someone point me to some documentation / How-tos on this ? </p>

<p>Thanks, 
Sagnik</p>
"
9471	How to recieve an array over Publisher and Subscriber? (Python)	"<p>Examples would be useful.</p>
"
9511	How do I use a webcam in ROS?	"<p>Is there a generic driver for webcams to get images on a ROS topic?</p>
"
9512	where did turtle_tf_sensor.launch go?	"<p>In the tf tutorial page:
<a href=""http://www.ros.org/wiki/tf/Tutorials/Using%20Stamped%20datatypes%20with%20tf%3A%3AMessageFilter"">uisng time stamped datatypes with tf</a>
the first line says to run a launch file that does not exist in diamondback.</p>

<p>roslaunch turtle_tf turtle_tf_sensor.launch </p>

<p>I would be really nice to see this example.  Any ideas where it has gone?</p>
"
9545	KDL for arm	"<p>I'm trying to build a KDL representation of an arm. I am confused by what kind DH used. One kind is rotating z then rotating x axis. Another is rotating x then rotating z axis. My model is the latter. which one does the KDL library use?</p>
"
9553	How to write node for collecting data from P3AT robot	"<p>I have question. I wish to collect velocity (left and right speed)data from Pioneer 3AT, and for that write node, and that data i want to use for odometry.
I ask if someone can me direct on right path. There are some tutorials but i dont know which i need to look. If someone have idea, please to give me some suggestion. 
Thanks! </p>
"
9588	Has anyone worked with the Clearpath Robotics Husky A200?	"<p>I am wondering if anyone has worked with the Clearpath Robotics Husky A200 platform under ROS. <br/>
Specifically I would like to know: 
1. Does the ROS API give you enough flexibility?
2. What hardware do you use to interface with it? (i.e. laptop, netbook, microATX board)
3. What additional sensors have you used with it?
Thanks!</p>
"
9637	Changing opencv2 installation options & recompiling	"<p>Hi,</p>

<p>I'd like to rebuild the opencv2 package with ffmpeg turned on (default is off). I used roscd to switch to opencv2 and sudo-edited the Makefile to turn the ffmpeg flag on. But now I don't know how to recompile the package. I tried renaming ROS_NOBUILD, but then rosmake gives me error about not having permission to rm several files.</p>

<p>Any suggestions on how to recompile?</p>

<p>~Robin</p>
"
9640	Rotation error in Gazebo simulation	"<p>Hi everywhere. I wrote the following robot model in URDF and then I built a controller to teleoperate with it.</p>

<p>The result, as you can see in the video is not the expected, since they rotate on itself doing strange things (which seems more difficult when the spin is somehow aligned with the axis of coordinates of the world). Any ideas? I tried to change values ​​<strong>Mu1, Mu2, Kp, Kd</strong> and others like <strong>selfCollide</strong> with no success. I compared with models such as the Erratic and PR2 and finds no difference to me.</p>

<p><a href=""http://www.youtube.com/watch?v=1gkuQO81AiQ"">Here is the video that I recorded with the problem.</a></p>

<p>Thanks!</p>

<p>P.S: I want to add that the result is the same in teleoperation and in applying joint efforts directly to the wheels. With this I want to say that there <strong>is not a problem of the controller</strong>.</p>
"
9686	How to programatically set the 2D pose on a map ?	"<p>How do I programatically set the the initial 2D pose estimate on a map when running acml and move_base - equivalent to the ""2D pose estimate"" button within Rviz ?</p>
"
9693	Import movie file (MPEG/AVI/MOV) into rosbag	"<p>Is there any way to import an MPEG movie file into a rosbag format?</p>

<p>I have some video recorded off of an HD digital camera that I want to do various processing on (camera calibration and ar_pose), but I'm not sure how to get it into a format that I can use in ROS.</p>
"
9766	ros_package_path	"<p>Hi,</p>

<p>Can you tell me the default ROS_PACKAGE_PATH please?</p>

<p>Also, is the faulty ROS_PACKAGE_PATH the reason why I continue receiving the error ""No arguments could be parsed into valid package or stack names"" while I'm trying to install the joy package?</p>

<p>Thank you!</p>

<p>Soe</p>
"
9768	Large number of DNS queries	"<p>So there was a situation on our campus network with a computer talking to a networked ROS core that generated 9,172,713 DNS queries over a few hours.  The machine that issued the requests was NOT the roscore.  Is this normal or is something likely configured incorrectly?</p>

<p>I've only run on private wifi routers, so I've never had IT report extreme DNS usage. :)</p>
"
9807	Is the Kinect's IMU being used on the TurtleBot?	"<p>I seem to recall that the TurtleBot is using an IMU other than the accelerometer built into the Kinect.  Is this true?  And if so, what are the limitations of the Kinect's IMU that prevent it from being used instead?</p>

<p>Thanks!</p>
"
9815	Recommended system for complex ROS programs + simulations	"<p>I am looking to build a new computer to run ROS, rviz, and gazebo simulations. I've previously been working on an underpowered Ubuntu VM. What specs (RAM, CPU, GPU...) would you recommend for complex operations like simulating a PR2 or point cloud manipulations? I definitely cannot spend more than <strong>$4,000</strong> so I think dual six core xeon processors are out :-p</p>

<p>Thanks - Patrick</p>
"
9902	Monocular Vslam	"<div class=""snippet""><p>I am unable to get vslam_system 's run_mono to work on the 3VD &amp; Versailles Rond datasets. It says ""Returning a small amount of good points: 0, minGoodPts = 30"".</p>

<p>Also after running SBA the error is of the order 10^3.</p>

<p>""Running SFM<br/>Final error: 2074.372325""</p>

<p>What could be going wrong? Has anyone managed to run ""run_mono"" on any published dataset?</p>

<hr/>

<p>Sorry, I did not post additional detail last time. <br/>
I am running a Ubuntu 10.10 with ROS diamondback. I installed the latest stable version of vslam stack and tried to run the monocular pipeline. <br/>
The previous post was, however, from a fedora 14 system and used run_mono executable provided with the ros package vslam_stack. <br/> <br/>
This time, I have compiled a small snippet of code that adds frames to an instance of VslamSystemMono using the addFrame function specified in the api. I initially encountered the same error as mentioned link:<a href=""http://answers.ros.org/question/1280/trying-to-run-vslam_system-on-mono-video-data"">here</a> <br/>
I corrected this problem with the same fix provided yesterday by link. <br/>
The monocular pipeline is however unable to find good matches. The number of inliers is ~0-4 and this is less than the minimum number of inliers(30). Also the error after running SBA is very high (~1000's).<br/> <br/>
I used camera parameters - 1.2 1.2 0 0 1 <br/>
Posted here is the output corresponding to two calls to ""addFrame"" function of VslamSystemMono class.<br/> <br/></p>

<pre>[ INFO] [1314008351.193699104]: Added frame to Mono Vslam system
called PoseEstimator2d::estimate for frames 1 and 2
Number of points: 92, number of matches: 100
extractPnPData: frame1.pts.size() = 92
extractPnPData: good points 0
Running SFM
Final error: 33044.761933
Dumping SFM returned r
3.128635 
-0.279981 
-0.019429
Dumping SFM return T
267.161316 
3770.465820 
9.712806 
The number of epipolar inliers: 53
53 points before filtering
35 points left after filtering
sba got 35 points
Node projection matrix
1.2   0   0  -0
  0 1.2   0  -0
  0   0   1  -0
Node projection matrix
    1.18084   -0.213058  -0.0148276     320.594
  -0.213064    -1.18093 0.000851121     4524.56
  -0.012286  0.00149597   -0.999923     9.71281
Added 35 points, 35 tracks
sba.tracks.size = 35
costProj done
sba.tracks.size = 35
costProj done
Errors after sba initialization: 168.142901 896.277610
[SBAsys] Cameras: 2   Points: 35   Projections: 70  Hessian elements: 105
[SBAsys] Average 2 projections per track and 35 projections per camera
[SBAsys] Checking camera order in projections...ok
[SBAsys] Number of invalid projections: 0
[SBAsys] Number of null tracks: 0  Number of single tracks: 0   Number of double tracks: 35
[SBAsys] Number of disconnected cameras: 0
[SBAsys] Number of cameras with &lt;5 projs: 0
[SBAsys] Number of camera connections: 0  which is 0 connections per camera and 50 percent matrix fill
[SBAsys] Min connection points: 1000000  Max connection points: 0  Average connection points: -nan
[SBAsys] Total connection projections: 0
[SBAsys] Connections with less than 5 points: 0   10 pts: 0   20 pts: 0   50 pts: 0
sba pointer: 0xbfc1d35c

Removed 22 projections &gt; 2 pixels ...</pre></hr/><span class=""expander""> <a>(more)</a></span></div>"
9922	What is the actual size of point cloud from a kinect.	"<p>Hello, all.</p>

<p>As far as I know a kinect provides 640x480x3 size of 2D image data (widthxheightxRGB) and
640x480x(sizeof a point in 3D). </p>

<p>Is there anyone who knows the actual size of a point cloud?</p>

<p>640x480x4x3 ? widthxheightx(float)x(x,y,z) ?</p>

<p>Cheers.</p>
"
9942	Goals and Navigation in dynamic maps using GMapping	"<p>Hello Everyone,</p>

<p>Lately I've been experimenting on using the navigation stack without the mapserver, and using GMapping for the generation of a map via Online SLAM, with very good results (although sometimes a little CPU intensive).</p>

<p>I was wondering how could I refer to a point the robot has visited in the past, when the map is continually changing. Here is an example of my question:</p>

<p>Suppose I am giving my robot a tour of the office (he doesn't have a prior knowledge of its environment). While we tour, at certain positions I will ""mark"" some place, for example, ""this is Ben's desk"". After the tour, I would like to be able to tell the robot to go to Ben's desk.</p>

<p>I am not sure how I could manage to do that if the map is continually changing, in size, orientation, etc. Is there a way that doesn't rely exclusively on odometry?</p>

<p>Thanks in advance. All ideas are welcome :)</p>
"
9943	Is there functionality built into ros to get nodes to print a stacktrace on crash?	"<p>When ROS nodes crash, modifying launch files to run under gdb is often required to get a stack trace. And a full reattempt to produce the conditions of the crash is necessary.</p>

<p>75% of crash failures (made up number :) could probably be solved without running in the debugger if we could see where the crash happened on each failure.</p>

<p>Is there functionality built into ROS to handle this?</p>
"
9977	perception pcl	"<p>Hi,</p>

<p> Currently I am trying tutorial for PCL as described in  <a href=""http://www.pointclouds.org/documentation/tutorials/using_pcl.php#using-pcl"">http://www.pointclouds.org/documentat...</a></p>

<p>But, as in perception_pcl package in ros I could not find file named ""FindPCL.cmake"".</p>

<p>Perhaps, someone could give some enlightenment here.
I am still a bit confused how to use pcl in ros.</p>

<p>Thanks in advanced.</p>

<p>Kang</p>
"
10026	turtlesim_node wont start on MAC OSX 10.6	"<p>Im trying to start with ROS, so im following the tutorials, my problem comes when I want to launch turtlesim_node by using the command rosrun turtlesim turtlesim_node. It says:</p>

<p>[rosrun] Couldn't find executable named turtlesim_node below /Users/ME/ros/ros_tutorials/turtlesim</p>

<p>Then i try:
rosmake turtlesim and i got these errors:</p>

<p>""wxBitmap::wxBitmap(int, int, int)"", referenced from:
        turtlesim::TurtleFrame::TurtleFrame(wxWindow<em>)in turtle_frame.o
    ""_wxDefaultPosition"", referenced from:
turtlesim::TurtleFrame::TurtleFrame(wxWindow</em>)in turtle_frame.o
  ld: symbol(s) not found
  collect2: ld returned 1 exit status
  make[3]: <strong>* [../bin/turtlesim_node] Error 1
  make[2]: <em></em></strong><em> [CMakeFiles/turtlesim_node.dir/all] Error 2
  make[1]: *</em>* [all] Error 2</p>

<p>any idea what could be wrong?
thanks in advance</p>
"
10027	who is heading the development of ROS?	"<p>I would like to contact the person in charge for the development of ROS at Willow Garage.
I <strong>don't</strong> mean the CEO of the entire company, just the project leader that is coordinating the development of ROS.
Do you know who he/she is and how to contact him/her?</p>
"
10038	Getting point cloud data from the kinect	"<p>hi guys, i am new to kinect. I need point cloud data from the depth camera in kinect. Any of you have any idea how to go about doing it? i am using ROS diamondback and Ubuntu.</p>
"
10047	Sequentially get the IR and RGB data from openni_node	"<p>Hello, all, </p>

<p>Since I want to do the processing toward the IR and RGB data from Kinect in one node, I need to build two subscribers and then iteratively subscribing the IR and RGB data published by openni_node within the openni_camera_unstable package. 
(Due to the limitation of Kinect:Cannot stream RGB and IR at the same time.)
But I have no idea how to code that out. Is there anyone would like to give me any advice or samples? Thanks a lot!</p>
"
10110	displaying of pointcloud crashes rviz	"<p> I am using pcl and pcl_ros from
 <a href=""http://svn.pointclouds.org/ros/tags/unstable/perception_pcl/"">http://svn.pointclouds.org/ros/tags/u...</a> .
I am publishing the pointcloud version .PCD v.7 using
pcd_to_pointcloud tool and then trying to display it in diamondback
version of rviz. </p>

<p>The latter however crashes rviz with the following message:
""""""
rviz: /tmp/buildd/ros-diamondback-visualization-common-1.4.0/debian/ros-diamondback-visualization-common/opt/ros/diamondback/stacks/visualization_common/ogre/build/ogre_src_v1-7-1/OgreMain/include/OgreAxisAlignedBox.h:252:
void Ogre::AxisAlignedBox::setExtents(const Ogre::Vector3&amp;, const
Ogre::Vector3&amp;): Assertion `(min.x &lt;= max.x &amp;&amp; min.y &lt;= max.y &amp;&amp; min.z
&lt;= max.z) &amp;&amp; ""The minimum corner of the box must be less than or equal
to maximum corner""' failed.
(0) : fatal error C9999: <strong>* exception during compilation *</strong>
""""""</p>

<p>I suspect it to be caused by NaNs in my pointcloud but then again this
was not the problem for diamondback version of pcl_ros.
Can anyone confirm if my guess is right and what would would the
action to rectify the problem be?</p>

<p>D.</p>
"
10120	Error building rosjava.jar	"<p>I'm trying to install rosjava from the official instructions: <a href=""http://code.google.com/p/rosjava/wiki/Welcome"">http://code.google.com/p/rosjava/wiki/Welcome</a></p>

<p>but I'm stuck at the step where I have to build rosjava.jar. When I type <code>ant dist</code>, I get this:</p>

<pre><code>BUILD FAILED
/opt/ros/javagooglecode/rosjava/build.xml:5: The following error occurred while executing this line:
/opt/ros/javagooglecode/rosjava/build-common.xml:16: The following error occurred while executing this line:
/opt/ros/javagooglecode/rosjava/dependencies.xml:20: The following error occurred while executing this line:
/opt/ros/javagooglecode/rosjava/android/build.xml:6: The following error occurred while executing this line:
/opt/ros/javagooglecode/rosjava/android/library/build.xml:37: Cannot find ${sdk.dir}/tools/ant/pre_setup.xml imported from /opt/ros/javagooglecode/rosjava/android/library/build.xml
</code></pre>

<p>I followed the solution presented here: <a href=""http://stackoverflow.com/questions/6159909/ant-cannot-firn-pre-setup-xml-for-an-android-project"">http://stackoverflow.com/questions/6159909/ant-cannot-firn-pre-setup-xml-for-an-android-project</a>, but it did not change anything.</p>

<p>Note than when I type android, it is not a recognized command, so I have to type the full path the to Android installation folder on my desktop. I don't know if this could be a problem.</p>
"
10130	rosnode list for not active nodes	"<p>Hi,</p>

<p>I'm creating something like an IDE for ROS. Is it possible to get a list of all available nodes. Something like 'rosnode list' but for the not yet started nodes.
I think 'rosrun TAB TAB ' displays them, but this needs manual input of the TAB-key. Maybe there is a way to use the autocompletion-feature in a shellscript.</p>

<p>Thanks for the help!</p>
"
10143	Parsing 3D txt data set	"<p>Hello!I've obtained a 3D data set and its stored in a txt file, the question would be how it is possible to load it into RViz? Thank you.</p>

<p>Im trying to build up a PointCloud message, the 3D data set is loaded from a vector, im stucked how to insert the values of pC into cloud.channels.values. In this way there is no msg reeived in RViz.</p>

<pre><code>sensor_msgs::PointCloud cloud;
    cloud.header.stamp = ros::Time::now();
    cloud.header.frame_id = ""/base_link"";

    cloud.channels.resize(1);
    int32_t countX = 24120;
    int32_t countY = 24120;
    int32_t countZ = 24120;
    int32_t total = countX * countY * countZ; 
    cloud.points.resize(total);

    cloud.channels[0].values.resize(total);
    cloud.channels[0].name = ""rgb"";     

    while (it &lt; myvector.end())
    {
          geometry_msgs::Point32&amp; pC = cloud.points[i]; 
          pC.y = *(it) * 0.001;
          myfile2 &lt;&lt; *(it++) * 0.001 &lt;&lt;""\n"";
          pC.x = *(it) * 0.001;
          myfile2 &lt;&lt; *(it++) * 0.001 &lt;&lt;""\n"";
          pC.z = *(it) * 0.001;
          myfile2 &lt;&lt; *(it++) * 0.001 &lt;&lt;""\n"";

          cloud.channels[0].values[i++] = 1.0f;                       
     }
     myfile2.close();
     cloud_pub.publish(cloud);
</code></pre>
"
10145	Navigation Stack + Hokuyo_node	"<div class=""snippet""><p>Ok, so I've been working with the navigation stack and I'm confused as to how to connect the hokuyo_node to everything.  I keep getting the error  </p>

<p>Message from [/hokuyo_node] has a non-fully-qualified frame_id [laser]. Resolved locally to [/laser].  This is will likely not work in multi-robot systems.  This message will only print once. </p>

<p>and for everything I've tried nothing seems to get me past this. I was under the impression that AMCL would output what was needed from the laser data.  My laser data tested in rviz seems to be fine.</p>

<p>Thanks ahead of time, and if you need more information that is question specific ill try to get it asap.</p>

<p>Edit 1 &lt;----------------------------------------------&gt;
I'v been working through the navigation stack tutorials, as well as following the Ardros blog. and most of the stuff is the same for both.</p>

<p>my robot configuration launch file.</p>

<pre><code>&lt;launch&gt;
&lt;node pkg=""tf"" type=""static_transform_publisher"" name=""base_to_laser_broadcaster"" args=""0 0 0 0 0 0 base_link base_laser 100"" /&gt;
&lt;node name=""hokuyo"" pkg=""hokuyo_node"" type=""hokuyo_node"" respawn=""false"" output=""screen""&gt;
    &lt;param name=""frame_id"" type=""str"" value=""base_laser""/&gt; 
    &lt;!-- Set the port to connect to here --&gt;
    &lt;param name=""port"" type=""string"" value=""/dev/ttyACM0""/&gt; 
    &lt;param name=""intensity"" type=""bool"" value=""false""/&gt;
&lt;/node&gt;
&lt;node name=""arduino"" pkg=""ardros"" type=""arduino.py""&gt;
    &lt;rosparam file=""$(find ardros)/info/ardros.yaml"" command=""load"" /&gt;
&lt;/node&gt;
</code></pre>

<p>&lt;/launch&gt;</p>

<p>Then my move_base.launch file</p>

<pre><code>&lt;launch&gt;
&lt;!-- Run the map server --&gt;
    &lt;node name=""map_server"" pkg=""map_server"" type=""map_server"" args=""$(find ardros)/maps/map.pgm 0.05""/&gt;
&lt;!--- Run AMCL --&gt;
    &lt;include file=""$(find ardros)/launch/amcl_diff.launch"" /&gt;
&lt;node pkg=""move_base"" type=""move_base"" respawn=""false"" name=""move_base"" output=""screen""&gt;
    &lt;rosparam file=""$(find ardros)/info/costmap_common_params.yaml"" command=""load"" ns=""global_costmap"" /&gt;
    &lt;rosparam file=""$(find ardros)/info/costmap_common_params.yaml"" command=""load"" ns=""local_costmap"" /&gt;
    &lt;rosparam file=""$(find ardros)/info/local_costmap_params.yaml"" command=""load"" /&gt;
    &lt;rosparam file=""$(find ardros)/info/global_costmap_params.yaml"" command=""load"" /&gt;
    &lt;rosparam file=""$(find ardros)/info/base_local_planner_params.yaml"" command=""load"" /&gt;
&lt;/node&gt;
</code></pre>

<p>&lt;/launch&gt;</p>

<p>my amcl_diff.launch file</p>

<pre><code>&lt;launch&gt;
&lt;node pkg=""amcl"" type=""amcl"" name=""amcl"" output=""screen""&gt;
    &lt;!-- Publish scans from best pose at a max of 10 Hz --&gt;
    &lt;param name=""odom_model_type"" value=""diff""/&gt;
    &lt;param name=""odom_alpha5"" value=""0.1""/&gt;
    &lt;param name=""transform_tolerance"" value=""0.2"" /&gt;
    &lt;param name=""gui_publish_rate"" value=""50.0""/&gt;
    &lt;param name=""laser_max_beams"" value=""60""/&gt;
    &lt;param name=""min_particles"" value=""500""/&gt;
    &lt;param name=""max_particles"" value=""5000""/&gt;
    &lt;param name=""kld_err"" value=""0.05""/&gt;
    &lt;param name=""kld_z"" value=""0.99""/&gt;
    &lt;param name=""odom_alpha1"" value=""0.2""/&gt;
    &lt;param name=""odom_alpha2"" value=""0.2""/&gt;
    &lt;!-- translation std dev, m --&gt;
    &lt;param name=""odom_alpha3"" value=""0.8""/&gt;
    &lt;param name=""odom_alpha4"" value=""0.2""/&gt;
    &lt;param name=""laser_z_hit"" value=""0.5""/&gt;
    &lt;param name=""laser_z_short"" value=""0.05""/&gt;
    &lt;param name=""laser_z_max"" value=""0.05""/&gt;
    &lt;param name=""laser_z_rand"" value=""0.5""/&gt;
    &lt;param name=""laser_sigma_hit"" value=""0.2""/&gt;
    &lt;param name=""laser_lambda_short"" value=""0.1""/&gt;
    &lt;param name=""laser_lambda_short"" value=""0.1""/&gt;
    &lt;param name=""laser_model_type"" value=""likelihood_field""/&gt;
    &lt;!-- &lt;param name=""laser_model_type"" value=""beam""/&gt; --&gt;
    &lt;param name=""laser_likelihood_max_dist"" value=""2.0""/&gt;
    &lt;param name=""update_min_d"" value=""0.2""/&gt;
    &lt;param name=""update_min_a"" value=""0.5""/&gt;
    &lt;param name=""odom_frame_id"" value=""odom""/&gt;
    &lt;param ...</code></pre><span class=""expander""> <a>(more)</a></span></div>"
10166	SICK laser driver fails to start after initialization and handshake?	"<p>Dear all, </p>

<p>I am getting trying to connect SICK LMS200 to ROS, but get the following error after it finds the port, and the laser info. </p>

<pre><code>kris@IanCurtis:~/ros/$ rosrun sicktoolbox_wrapper sicklms

    *** Attempting to initialize the Sick LMS...
    Attempting to open device @ /dev/ttyUSB1
        Device opened!
    Attempting to start buffer monitor...
        Buffer monitor started!
    Attempting to set requested baud rate...
A Timeout Occurred!  2 tries remaining
A Timeout Occurred!  1 tries remaining
A Timeout Occurred - SickLIDAR::_sendMessageAndGetReply: Attempted max number of tries w/o success!
    Failed to set requested baud rate...
    Attempting to detect LMS baud rate...
        Checking 19200bps...
A Timeout Occurred!  2 tries remaining
A Timeout Occurred!  1 tries remaining
A Timeout Occurred - SickLIDAR::_sendMessageAndGetReply: Attempted max number of tries w/o success!
        Checking 38400bps...
        Detected LMS baud @ 38400bps!
        Operating @ 38400bps
    Attempting to sync driver...
        Driver synchronized!
    *** Init. complete: Sick LMS is online and ready!
    Sick Type: Sick LMS 200-30106
    Scan Angle: 180 (deg)
    Scan Resolution: 0.5 (deg)
    Measuring Mode: 8m/80m; 3 reflector bits
    Measuring Units: Centimeters (cm)

[ INFO] [1307303753.596993806]: Setting variant to (180, 0.500000)
    Requesting partial scan data stream...
        Data stream started!
[ERROR] [1307303753.973765819]: woah! error!
terminate called after throwing an instance of 'SickToolbox::SickThreadException'
Aborted
</code></pre>
"
10187	ROS and ADC/DAC Hardware	"<p>Three questions on ROS-hardware interface--</p>

<p>Has anyone used ROS with National Instruments DAQ Cards such as the PCI-6225?  It appears to be possible to run it under linux using the <a href=""https://groups.google.com/group/comedi_list/browse_thread/thread/f886fdaebb57adce?pli=1"">Comedi drivers</a>, but I don't have a good feel for how much work this would require.</p>

<p>In the same vein, does anyone have recommendations for library and/or hardware choices for motor controllers under ROS?  There appear to be <a href=""http://ros-users.122217.n3.nabble.com/motor-control-driver-CiA-DSP-402-EPOS-ELMO-td1997926.html#a2010998"">stacks for the EPOS/ELMO controlllers</a>, but I'd be curious to hear any feedback on how hard they are to set up, and on any other options.</p>

<p>Finally, what sort of latency could one expect from passing messages between ROS nodes on a fairly good machine running data acquisition (say a couple dozen analog inputs) and a few standard processing pipelines?  One user mentions <a href=""http://answers.ros.org/question/1015/publisher-subscriber-teleoperation-high-latency"">seeing up to 9ms</a> for a basic packet reflector, but also seems to think this is unexpectedly high.  Is it reasonable to tweak ROS to give &lt;1ms consistently for at least one or two important control loops?</p>
"
10222	openni_camera depth image opencv	"<p>Hi </p>

<p>I am Using opencv 2.2 and cv::bridge out of the ros diamondback deb packages. I changed the Makefile of opencv to get a newer version of opencv (Revision 5427) </p>

<p>I convert the <code>const sensor_msgs::ImageConstPt</code> to <code>cv_bridge::CvImagePtr</code> with </p>

<pre><code>cv_ptr_depth_ = cv_bridge::toCvCopy(depth_image_msgs, sensor_msgs::image_encodings::TYPE_32FC1);
</code></pre>

<p>With <code>cv::VideoWriter</code> I want to store the depth image as an avi file. That works fine for the rgb image that is converted to <code>sensor_msgs::image_encodings::BGR8</code> but not for the depth image. The <code>cv::VideoWriter</code> needs images with depth = IPL_DEPTH_8U and nChannels = 1.</p>

<p>But I cannot convert the 32FC1 type in 8UC1</p>

<p>How can I handle this problem?</p>

<p>Thanks 
Stefan </p>
"
10245	cannot find roscpp when following tutorial 3	"<p>hey all,
i'm following the ROS tutorial 3 in which it teaches how to create a new package which has dependencies.
when i enter the following:
$ roscreate-pkg beginner_tutorials roscpp rospy std_msgs
terminal shoots back:
ERROR: dependency [roscpp] cannot be found</p>

<p>note : i've updated the ROS_PACKAGE_PATH variable.
i have verified manually and (with rospack find also) that roscpp actually exists in my filesystem. its just that roscreate cant seem to find it.</p>

<p>any help would be greatly appreciated.</p>
"
10329	Error trying to run rviz	"<p>Hi, I'm new in ros, when I try to run rviz on my laptop I get the following crash message:</p>

<p>The program 'rviz' received an X Window System error.</p>

<p>This probably reflects a bug in the program.</p>

<p>The error was 'BadWindow (invalid Window parameter)'.</p>

<p>(Details: serial 28 error_code 3 request_code 138 minor_code 4)
  (Note to programmers: normally, X errors are reported asynchronously;
   that is, you will receive the error a while after causing it.
   To debug your program, run it with the --sync command line
   option to change this behavior. You can then get a meaningful
   backtrace from your debugger if you break on the gdk_x_error() function.)</p>

<p>my laptop has an nvidia gts 360m and the version 260.19.44 of nvidia driver.</p>
"
10332	Throwing out recursive print.	"<p>Why am I getting this after pressing ""Ctrl+C""?</p>

<p>Warning: recursive print statement has occurred. Throwing out recursive print.</p>

<p>Warning: recursive print statement has occurred. Throwing out recursive print.</p>

<p>forever</p>

<p>I can't stop it!</p>
"
10335	ROS Answers Search Bar Broken?	"<p>At the risk of sounding foolish, is the ROS answers search bar broken?  It doesn't seem to operate at all like your traditional search bar, and as such I've found the site to be of very limited use.  For example, if you search for ""dsp"" it does not return any results, even though I'm sure this word is in a posted question and is also a tag. 
i.e. <a href=""http://answers.ros.org/question/1183/real-time-digital-signal-processing-dsp-library"">http://answers.ros.org/question/1183/real-time-digital-signal-processing-dsp-library</a></p>

<p>P.S. I've also tried searching for ""ROS"" and it has shown no results, but maybe this search term was purposefully removed.</p>
"
10338	table top segmentation from kinect	"<p>Hello,</p>

<p>Does anyone know how to best achieve table top object segmentation from kinect sensor? is there any module/tutorial you can recommend me to use?</p>
"
10343	How to run Rviz remotely	"<p>I assume that it's possible run run Rviz on a machine other than the one running the robot.  If so, how to I set the master address (the IP address of the robot) which Rviz should be subscribing to ?</p>
"
10356	Reduce Kinect Resolution	"<p>I want to reduce the resolution of the kinetic to speed up processing. For example ignoring every other pixel would reduce the resolution by half. Is there an easy way to do this using the current drivers?</p>

<p>On a similar note - is it possible to only look at one vertical or horizontal line of resolution and pretend my kinect is a laser scanner? Thanks!</p>
"
